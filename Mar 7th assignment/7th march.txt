Q1. What are the three measures of central tendency?

Mean: The mean is the sum of all the values in a dataset divided by the total number of values. It is also known as the average. The mean is sensitive to outliers.

Median: The median is the middle value in a dataset when the values are arranged in order. If the dataset has an even number of values, the median is the average of the two middle values. The median is less sensitive to outliers than the mean.

Mode: The mode is the value that appears most frequently in a dataset. A dataset may have multiple modes if there are several values that appear with the same frequency. The mode is useful for categorical data or data with a limited number of possible values.

Q2. What is the difference between the mean, median, and mode? How are they used to measure the
central tendency of a dataset?

Central tendency is a statistical concept that refers to a single value that represents the typical or central value of a dataset. Measures of central tendency provide information about where the data tends to cluster or concentrate. The three main measures of central tendency are the mean, median, and mode. The mean is the arithmetic average of all the values in the dataset, the median is the middle value in a dataset, and the mode is the most frequently occurring value. These measures are used to summarize and describe a dataset and help to better understand the underlying data distribution.

Mean: The mean is the sum of all the values in a dataset divided by the total number of values. It is also known as the average. The mean is sensitive to outliers.

Median: The median is the middle value in a dataset when the values are arranged in order. If the dataset has an even number of values, the median is the average of the two middle values. The median is less sensitive to outliers than the mean.

Mode: The mode is the value that appears most frequently in a dataset. A dataset may have multiple modes if there are several values that appear with the same frequency. The mode is useful for categorical data or data with a limited number of possible values.

Q3. Measure the three measures of central tendency for the given height data:

import numpy as np
import statistics as sc
a=np.array([178,177,176,177,178.2,178,175,179,180,175,178.9,176.2,177,172.5,178,176.5])
mean_=np.mean(a)
median_=np.median(a)
mode_=sc.mode(a)
print(mode_,median_,mode_)

Q4. Find the standard deviation for the given data:

import numpy as np
import statistics as sc
a=np.array([178,177,176,177,178.2,178,175,179,180,175,178.9,176.2,177,172.5,178,176.5])
standarn_deviation=np.std(a)
print(standarn_deviation)

Q5. How are measures of dispersion such as range, variance, and standard deviation used to describe
the spread of a dataset? Provide an example.

Measures of dispersion such as range, variance, and standard deviation are used to describe the spread of a dataset by providing information about how much the data deviates from the central tendency (mean, median, or mode).

Range is the simplest measure of dispersion and is defined as the difference between the largest and smallest values in the dataset. Range provides a rough estimate of the spread of the data. For example, the range of the dataset [3, 5, 6, 8, 10] is 7 (10 - 3).

Variance is a measure of how much the data varies from the mean of the dataset. It is calculated by taking the average of the squared differences between each value and the mean. A high variance indicates that the data points are spread out over a wider range, while a low variance indicates that the data points are tightly clustered around the mean. For example, the variance of the dataset [3, 5, 6, 8, 10] is approximately 6.8.

Standard deviation is the square root of the variance and is a widely used measure of dispersion. It provides an estimate of the average distance between each data point and the mean. A high standard deviation indicates that the data points are spread out over a wider range, while a low standard deviation indicates that the data points are tightly clustered around the mean. For example, the standard deviation of the dataset [3, 5, 6, 8, 10] is approximately 2.6.

For example, let's say we have two datasets:

Dataset A: [1, 3, 5, 7, 9]
Dataset B: [1, 2, 3, 8, 9]
Both datasets have the same mean of 5, but they have different spreads. Using the measures of dispersion, we can quantify the differences between the two datasets:

The range of Dataset A is 8 (9 - 1), while the range of Dataset B is 8 (9 - 1).
The variance of Dataset A is approximately 6.7, while the variance of Dataset B is approximately 9.3.
The standard deviation of Dataset A is approximately 2.6, while the standard deviation of Dataset B is approximately 3.0.
From these measures, we can see that Dataset B has a higher variance and standard deviation than Dataset A, indicating that the data points are more spread out. Therefore, Dataset B has a wider range of values and more variability in the data than Dataset A.

Q6. What is a Venn diagram?


A Venn diagram is a graphical representation used to show the relationships between sets. It consists of a series of overlapping circles or other shapes, where each circle represents a set and the overlap represents the relationship between the sets. Venn diagrams are often used in mathematics, statistics, and other fields to visualize the relationships between different groups of objects or data.

Each circle in a Venn diagram represents a set, and the area of the circle corresponds to the size of the set. The overlapping area between two or more circles represents the intersection of the sets. The area outside the circles represents the union of the sets.


Q7. For the two given sets A = (2,3,4,5,6,7) & B = (0,2,6,8,10). Find:
(i) (2,6)
(ii) A ⋃ B = (0,2,3,4,5,6,7,8,10)

Q8. What do you understand about skewness in data?

In statistics, skewness refers to the degree of asymmetry in the distribution of a dataset. A dataset is said to be skewed if it is not symmetrical around its mean. Skewness can be positive, negative, or zero, depending on the direction and degree of the asymmetry.

Positive skewness (right skewness) occurs when the long tail of the distribution is on the right-hand side, and the majority of the data is on the left-hand side. This means that the mean of the dataset is greater than the median. A common example of a positively skewed distribution is income data, where a small number of people have very high incomes, skewing the mean higher than the median.

Negative skewness (left skewness) occurs when the long tail of the distribution is on the left-hand side, and the majority of the data is on the right-hand side. This means that the mean of the dataset is less than the median. An example of a negatively skewed distribution is exam scores, where most students score high, but a small number of students score very low, skewing the mean lower than the median.

Zero skewness occurs when the distribution is symmetrical around its mean. This means that the mean and median of the dataset are equal.

Skewness can have an impact on the interpretation of statistical analyses. For example, if a dataset is positively skewed, the mean may not be a good representative of the central tendency of the data. In such cases, the median may be a better measure of central tendency. Additionally, skewness can affect the validity of some statistical tests that assume a normal distribution of data.

Therefore, it is important to consider skewness when analyzing data and choosing appropriate statistical methods. Skewness can be measured using various statistical tools, including skewness coefficients and graphical methods such as histograms and box plots.


Q9. If a data is right skewed then what will be the position of median with respect to mean?

If a dataset is right skewed, then the median will be less than the mean.

This is because in a right-skewed distribution, the tail of the distribution is longer on the right side, which means that there are more extreme values on the right side of the distribution. These extreme values can pull the mean in the direction of the tail, making it greater than the median. On the other hand, the median is less sensitive to extreme values and is only influenced by the middle value(s) of the dataset.

Q10. Explain the difference between covariance and correlation. How are these measures used in
statistical analysis?

Covariance and correlation are both measures of the relationship between two variables in a dataset. However, they differ in their units of measurement and interpretation.

Covariance is a measure of how two variables change together. It measures the extent to which two variables are linearly related. A positive covariance indicates that the two variables tend to increase or decrease together, while a negative covariance indicates that they tend to vary in opposite directions. The magnitude of the covariance depends on the units of measurement of the two variables, which makes it difficult to compare covariances across datasets. The formula for covariance is:

cov(X,Y) = (1/n) * ∑(Xi - Xbar)(Yi - Ybar)

Correlation is a standardized measure of the relationship between two variables. It measures the strength and direction of the linear relationship between the two variables. Unlike covariance, correlation is unitless and falls within the range of -1 to 1. A correlation of 1 indicates a perfect positive relationship, while a correlation of -1 indicates a perfect negative relationship. A correlation of 0 indicates no linear relationship. The formula for correlation is:

corr(X,Y) = cov(X,Y) / (std(X) * std(Y))

Correlation is a more commonly used measure of the relationship between two variables because it is easier to interpret and compare across datasets. Correlation values are always between -1 and 1, making it easier to compare the strength and direction of the relationship between two variables. In contrast, covariance values are affected by the units of measurement of the variables, which can make it difficult to compare covariances across datasets.

Both covariance and correlation are used in statistical analysis to understand the relationship between two variables. They can help identify patterns in data, make predictions about future values, and inform decision-making in various fields such as finance, economics, and engineering. However, it is important to remember that correlation does not imply causation, and further analysis may be required to determine the nature and direction of the relationship between two variables.

Q11. What is the formula for calculating the sample mean? Provide an example calculation for a
dataset.

The formula for calculating the sample mean is:

x̄ = (∑xi) / n

where x̄ represents the sample mean, ∑xi represents the sum of all the individual data points in the sample, and n represents the sample size.

To calculate the sample mean, we simply add up all the values in the sample and divide by the number of values. For example, consider the following dataset:

5, 7, 9, 11, 13
5 + 7 + 9 + 11 + 13 = 45
x̄ = 45 / 5 = 9

Q12. For a normal distribution data what is the relationship between its measure of central tendency?


For a normal distribution, the measures of central tendency, namely the mean, median, and mode, are equal to each other. This means that the peak of the distribution is at the center, and the distribution is symmetric.

This relationship holds true for any normal distribution, regardless of the mean and standard deviation. The symmetry of the normal distribution ensures that the mean, median, and mode are all located at the center of the distribution.

For example, consider a normal distribution with a mean of 10 and a standard deviation of 2. The mean, median, and mode of this distribution will all be equal to 10. Similarly, for a normal distribution with a mean of 0 and a standard deviation of 1, the mean, median, and mode will all be equal to 0.


Q13. How is covariance different from correlation?


Covariance and correlation are both measures of the relationship between two variables in a dataset. However, they differ in their units of measurement and interpretation.

Covariance is a measure of how two variables change together. It measures the extent to which two variables are linearly related. A positive covariance indicates that the two variables tend to increase or decrease together, while a negative covariance indicates that they tend to vary in opposite directions. The magnitude of the covariance depends on the units of measurement of the two variables, which makes it difficult to compare covariances across datasets.

Correlation, on the other hand, is a standardized measure of the relationship between two variables. It measures the strength and direction of the linear relationship between the two variables. Unlike covariance, correlation is unitless and falls within the range of -1 to 1. A correlation of 1 indicates a perfect positive relationship, while a correlation of -1 indicates a perfect negative relationship. A correlation of 0 indicates no linear relationship.

The key difference between covariance and correlation is that covariance is affected by the units of measurement of the two variables, whereas correlation is not. This means that it is easier to compare correlation values across datasets than it is to compare covariance values.

Another important difference is that correlation can only detect linear relationships between two variables, whereas covariance can detect any type of relationship between the two variables, linear or non-linear.

In summary, while both covariance and correlation are measures of the relationship between two variables, correlation is a more commonly used measure because it is standardized, unitless, and easier to interpret and compare across datasets.

Q14. How do outliers affect measures of central tendency and dispersion? Provide an example.


Outliers are data points that are significantly different from the rest of the data in a dataset. Outliers can have a significant effect on measures of central tendency and dispersion.

When a dataset contains outliers, the mean, which is the most commonly used measure of central tendency, can be heavily influenced by their values. The mean is calculated by summing all the values in the dataset and dividing by the number of values, so if an outlier has a very high or very low value, it can greatly increase or decrease the value of the mean. This can lead to a distorted representation of the data.

Outliers can also affect measures of dispersion, such as variance and standard deviation. These measures are calculated based on the differences between each data point and the mean. When outliers are present, they can greatly increase the variance and standard deviation, making the data appear more spread out than it actually is.

10, 12, 14, 16, 18, 20, 22, 100
(10 + 12 + 14 + 16 + 18 + 20 + 22 + 100) / 8 = 23
(10 + 12 + 14 + 16 + 18 + 20 + 22) / 7 = 15.71
((10-23)^2 + (12-23)^2 + (14-23)^2 + (16-23)^2 + (18-23)^2 + (20-23)^2 + (22-23)^2 + (100-23)^2) / 8 
= 1316.25
((10-15.71)^2 + (12-15.71)^2 + (14-15.71)^2 + (16-15.71)^2 + (18-15.71)^2 + (20-15.71)^2 + (22-15.71)^2) / 7
= 16.14
