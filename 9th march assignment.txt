Q1: Probability Mass Function (PMF) and Probability Density Function (PDF) are mathematical functions used to describe the distribution of a random variable. The PMF is used for discrete random variables and gives the probability of each possible outcome. The PDF is used for continuous random variables and gives the probability density at each point. For example, consider rolling a fair six-sided die. The PMF would give a probability of 1/6 for each of the six possible outcomes (1, 2, 3, 4, 5, or 6). The PDF would give a probability density for each possible value between 1 and 6, with a height of 1/6 at each integer value.

Q2: The Cumulative Density Function (CDF) is a function that gives the probability that a random variable takes a value less than or equal to a certain value. For example, the CDF for a fair six-sided die would start at 0 for x < 1, and then increase by 1/6 at each integer value of x up to x = 6, where it would reach a value of 1. The CDF is used to determine probabilities of intervals and can be used to find percentiles and quantiles.

Q3: The normal distribution is used as a model for many situations in which the variable being studied can be expected to be the result of the sum of many small independent effects. Examples include heights and weights of people, scores on standardized tests, and errors in measurements. The normal distribution is characterized by two parameters: the mean (µ), which determines the center of the distribution, and the standard deviation (σ), which determines the spread of the distribution. The normal distribution is symmetric and bell-shaped, with 68% of the data falling within one standard deviation of the mean, 95% falling within two standard deviations, and 99.7% falling within three standard deviations.

Q4: The normal distribution is important because it is a widely used model for many real-life phenomena. It allows us to make predictions and estimate probabilities based on the mean and standard deviation of the data. Examples of real-life phenomena that follow a normal distribution include heights and weights of people, IQ scores, and errors in measurements. The normal distribution is also important in hypothesis testing and statistical inference.

Q5: The Bernoulli distribution is a discrete probability distribution that describes the outcome of a single trial that can result in one of two outcomes, often labeled as success and failure. An example of the Bernoulli distribution is flipping a coin, where success could be defined as getting heads and failure could be defined as getting tails. The Binomial distribution is a discrete probability distribution that describes the number of successes in a fixed number of independent Bernoulli trials. The main difference between the Bernoulli distribution and the Binomial distribution is that the Bernoulli distribution describes a single trial, while the Binomial distribution describes the number of successes in a fixed number of trials.

Q6: To find the probability that a randomly selected observation will be greater than 60, we need to calculate the z-score and then use a standard normal distribution table or calculator. The formula for the z-score is z = (x - µ) / σ, where x is the observation, µ is the mean, and σ is the standard deviation. In this case, z = (60 - 50) / 10 = 1. The probability of a standard normal distribution being greater than 1 is 0.1587, so the probability of the original distribution being greater than 60 is 0.1587.

Q7: The uniform distribution is a continuous probability distribution in which all values in a given interval have the same probability density. For example, rolling a fair six-sided die can be modeled with a uniform distribution, where each outcome (1, 2, 3, 4, 5, or 6) has an equal probability of 1/6. Another example is choosing a random number between 0 and 1, where each value between 0 and 1 has an equal probability density of 1.

Q8: The z-score, also known as the standard score, is a measure of how many standard deviations a data point is from the mean of the data set. It is calculated as (x - µ) / σ, where x is the data point, µ is the mean, and σ is the standard deviation. The z-score is important because it allows us to compare data points from different normal distributions on a common scale. It also helps us identify outliers and extreme values in a data set.

Q9: The Central Limit Theorem (CLT) is a statistical theorem that states that as the sample size increases, the distribution of the sample means approaches a normal distribution, regardless of the shape of the population distribution. This means that if we take multiple random samples from a population and calculate the mean of each sample, the distribution of those sample means will be approximately normal, with a mean equal to the population mean and a standard deviation equal to the population standard deviation divided by the square root of the sample size. The significance of the CLT is that it allows us to use the normal distribution to make inferences about the population mean, even if the population distribution is unknown or non-normal.

Q10: The assumptions of the Central Limit Theorem include:

The sample is random and independent.
The sample size is sufficiently large (usually n ≥ 30).
The population distribution has a finite mean and variance (or is normal). If the population is not normal, the sample size needs to be even larger for the CLT to hold.
